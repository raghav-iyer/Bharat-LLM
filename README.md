Decoder Only Transformer with Multihead Self Attention, Rotatory positional embedding, sentence piece vocab, inbuilt tokenizer ,new architeecture for LLM
